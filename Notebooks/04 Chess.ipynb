{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7387ba3b-c578-40f6-8f2f-465daeea6d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import chess\n",
    "from chess import svg, Move\n",
    "from chess.svg import Arrow\n",
    "\n",
    "from ipywidgets import interact\n",
    "from IPython.display import display, HTML, clear_output\n",
    "\n",
    "from pypad.alpha_zero import AlphaZero, PytorchNeuralNetwork\n",
    "\n",
    "from pypad.games import Chess\n",
    "from pypad.states import ChessState\n",
    "from pypad.states.chess_enums import ObsPlanes, ActionPlanes, KeyGames\n",
    "\n",
    "GAME_NAMES = KeyGames.labels()\n",
    "OBS_NAMES = ObsPlanes.labels()\n",
    "ACTION_NAMES = ActionPlanes.labels()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d03541-827d-4cb1-a9ab-b144284cc295",
   "metadata": {},
   "source": [
    "#  Fen Inspector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922650fe-76ef-4738-ad59-620d6d981fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "game = Chess()\n",
    "state = game.initial_state('4Qbk1/2r4p/5Rp1/3p4/8/5N1P/3NBPPK/2r5 b - - 0 33')\n",
    "state.board"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27055acc-bfcf-438e-a66f-d0c27329622e",
   "metadata": {},
   "source": [
    "# View Key Games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9665aaa6-af0c-45f2-88dc-9d66ee972412",
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_key_games(label: str, move_count: int, flip: bool):\n",
    "    sans = KeyGames.get(label)\n",
    "    state = game.initial_state(sans[:move_count])\n",
    "    board = state.board\n",
    "    lastmove = board.move_stack[-1] if board.move_stack else None\n",
    "    return svg.board(board, flipped=flip and not board.turn, size=350, lastmove=lastmove)\n",
    "\n",
    "_ = interact(view_key_games, label=GAME_NAMES, move_count=range(445), flip=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0942117-5cc5-47d4-977a-d42c583d7802",
   "metadata": {},
   "source": [
    "# Input Feature Planes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a4534c-520e-4d44-84bf-ab7944ab64de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_observation_planes(label: str, plane_name: str, move_count: int):\n",
    "    sans = KeyGames.get(label)\n",
    "    state = game.initial_state(sans[:move_count])\n",
    "    board = state.board\n",
    "    \n",
    "    plane_idx = ObsPlanes.get(plane_name)\n",
    "    state.plot(plane_idx)\n",
    "\n",
    "    lastmove = board.move_stack[-1] if board.move_stack else None\n",
    "    return svg.board(board, flipped=not board.turn, size=350, lastmove=lastmove)\n",
    "\n",
    "_ = interact(inspect_observation_planes, label=GAME_NAMES, plane_name=OBS_NAMES, move_count=range(445))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b52ed9-d2f2-4dfa-b4bb-5470732d83a4",
   "metadata": {},
   "source": [
    "# Inspect Action Planes - Legal Moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a14ea5c-bee6-4471-be1c-483560a08ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_policy_planes(label: str, plane_name: str, move_count: int):\n",
    "    sans = KeyGames.get(label)\n",
    "    state = game.initial_state(sans[:move_count])\n",
    "    board = state.board\n",
    "\n",
    "    legal_moves = state.status().legal_moves\n",
    "    plane = ActionPlanes.get(plane_name)\n",
    "    state.plot_policy(plane)\n",
    "    \n",
    "    arrows = [Arrow(move.from_square, move.to_square) for move in legal_moves if state.policy_loc_3d(move)[0] == plane]\n",
    "    lastmove = board.move_stack[-1] if board.move_stack else None\n",
    "    return svg.board(board, flipped=not board.turn, size=350, lastmove=lastmove, arrows=arrows)\n",
    "\n",
    "_ = interact(inspect_policy_planes, label=GAME_NAMES, plane_name=ACTION_NAMES, move_count=range(200))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d8ba78-7aae-46bc-bc4b-54b32ace3d64",
   "metadata": {},
   "source": [
    "# Visualising Model predictions for Chess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290868b4-047c-45bc-bf2d-8f89983b828c",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = PytorchNeuralNetwork.create(game, '..')\n",
    "alpha_zero = AlphaZero(network)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088db3da-242a-40d6-945a-bf18efabfedf",
   "metadata": {},
   "source": [
    "## Top moves by action plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f57cfa3-b1f6-4d36-964b-86fa12765ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_policy_planes(label: str, plane_name: str, move_count: int, moves_to_show: int):\n",
    "    sans = KeyGames.get(label)\n",
    "    state = game.initial_state(sans[:move_count])\n",
    "    board = state.board\n",
    "\n",
    "    legal_moves = state.status().legal_moves\n",
    "    plane = ActionPlanes.get(plane_name)\n",
    "    \n",
    "    policy = alpha_zero.raw_policy(state)\n",
    "    state.plot_policy(plane, policy)\n",
    "    \n",
    "    indices = np.argpartition(policy.encoded_policy, -moves_to_show)[-moves_to_show:]\n",
    "    arrows = [Arrow(move.from_square, move.to_square) for move in legal_moves if state.policy_loc_3d(move)[0] == plane and state.policy_loc(move) in indices]\n",
    "    lastmove = board.move_stack[-1] if board.move_stack else None\n",
    "    return svg.board(board, flipped=not board.turn, size=350, lastmove=lastmove, arrows=arrows)\n",
    "\n",
    "_ = interact(inspect_policy_planes, label=GAME_NAMES, plane_name=ACTION_NAMES, move_count=range(200), moves_to_show=(1,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9808bdc5-4121-4522-87e0-33bbb8d214a2",
   "metadata": {},
   "source": [
    "## Top moves (all planes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daca5201-c441-4dca-a8e5-47109f8d5b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_policy_planes(label: str, move_count: int, moves_to_show: int):\n",
    "    sans = KeyGames.get(label)\n",
    "    state = game.initial_state(sans[:move_count])\n",
    "    board = state.board\n",
    "\n",
    "    policy = alpha_zero.raw_policy(state)\n",
    "    state.plot_policy(-1, policy)\n",
    "    \n",
    "    legal_moves = state.status().legal_moves\n",
    "    indices = np.argpartition(policy.encoded_policy, -moves_to_show)[-moves_to_show:]\n",
    "    arrows = [Arrow(move.from_square, move.to_square) for move in legal_moves if state.policy_loc(move) in indices]\n",
    "    lastmove = board.move_stack[-1] if board.move_stack else None\n",
    "    return svg.board(board, flipped=not board.turn, size=350, lastmove=lastmove, arrows=arrows)\n",
    "\n",
    "_ = interact(inspect_policy_planes, label=GAME_NAMES, move_count=range(200), moves_to_show=(1,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608bb0b6-42ff-4501-aeef-b4a0c620f457",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_policy_planes(label: str, move_count: int, moves_to_show: int, num_mcts_sims: int):\n",
    "    sans = KeyGames.get(label)\n",
    "    state = game.initial_state(sans[:move_count])\n",
    "    board = state.board\n",
    "\n",
    "    policy = alpha_zero.policy(state, num_mcts_sims)\n",
    "    state.plot_policy(-1, policy)\n",
    "    \n",
    "    legal_moves = state.status().legal_moves\n",
    "    indices = np.argpartition(policy.encoded_policy, -moves_to_show)[-moves_to_show:]\n",
    "    arrows = [Arrow(move.from_square, move.to_square) for move in legal_moves if state.policy_loc(move) in indices]\n",
    "    lastmove = board.move_stack[-1] if board.move_stack else None\n",
    "    return svg.board(board, flipped=not board.turn, size=350, lastmove=lastmove, arrows=arrows)\n",
    "\n",
    "sims = [2, 100, 200, 500, 1_000, 2_000, 5_000]\n",
    "_ = interact(inspect_policy_planes, label=GAME_NAMES, move_count=range(200), moves_to_show=(1,10), num_mcts_sims=sims)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc842b8-faf7-48d8-80f4-53f87ad342b4",
   "metadata": {},
   "source": [
    "# Play against Alpha Zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bb43ac-06a5-4a25-9e7f-b5e1fd72f5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "game = Chess()\n",
    "state = game.initial_state()\n",
    "challenger_plays_as = 1 # play as Player: 1 or 2\n",
    "\n",
    "network = PytorchNeuralNetwork.create(game, '..')\n",
    "alpha_zero = AlphaZero(network)\n",
    "\n",
    "network_old = PytorchNeuralNetwork.create(game, '..', 20)\n",
    "alpha_zero_old = AlphaZero(network_old)\n",
    "\n",
    "def get_move(i: int) -> int:\n",
    "    if i % 2 == challenger_plays_as:\n",
    "        return alpha_zero.select_move(state, 100)\n",
    "    else:\n",
    "        return state.get_input_move()\n",
    "        # return alpha_zero_old.select_move(state, 60)\n",
    "\n",
    "while state.status().is_in_progress:\n",
    "    clear_output(); display(state.board) \n",
    "    move = get_move(state.move_count)\n",
    "    state.set_move(move)\n",
    "\n",
    "clear_output(); display(state.board)\n",
    "if state.status().value > 0:\n",
    "    print('Challenger wins!' if state.played_by == challenger_plays_as else \"AlphaZero wins!\")\n",
    "else:\n",
    "    print(\"It's a draw!\")\n",
    "\n",
    "print(state.pgn())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
