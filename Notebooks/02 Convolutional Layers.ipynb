{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad23fcc6-da2a-4a15-92d0-56bc7f9512c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from pypad.games import ConnectX, TicTacToe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f812f10-634b-42e8-b64e-b858c983ef3d",
   "metadata": {},
   "source": [
    "# Describing TicTacToe with a Convolutional Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377dab47-1c9c-473b-ae9c-4cbe322225d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tictactoe = TicTacToe()\n",
    "tictactoe_state = tictactoe.initial_state(\"0,1,5\")\n",
    "\n",
    "tictactoe_state.plot()\n",
    "tictactoe_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bb94a5-a071-45a9-aa31-181a4d2ce606",
   "metadata": {},
   "source": [
    "# Describing TicTacToe with a Convolutional Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb5ff06-fdb0-4c51-b1e8-4c2c5110c655",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "connectx = ConnectX()\n",
    "connectx_state = connectx.initial_state([3,3,4,5,3,4,5,5,6,1,1,1,1,1,1,2,6,6,7,7])\n",
    "\n",
    "connectx_state.plot()\n",
    "connectx_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55d4803-811f-4ca6-9aae-df53c9c3a40e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Understanding the action of a convolutional layer using ConnectX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27b75f4-e59c-49a7-a929-b9b62f88eaae",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "in_channels = 3 # e.g. three RGB channels\n",
    "out_channels = 3 # e.g. three RGB channels\n",
    "kernel_size = 2 # usually odd number is better because padding = (KS - 1) // 2\n",
    "\n",
    "# Create a convolutional layer with (out_channels x in_channels x kernel_size x kernel_size) weights\n",
    "conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=1)\n",
    "\n",
    "t_new = torch.tensor([\n",
    "         # red to red (1 to 1)\n",
    "        [[[ 0.0000,  0.0000],\n",
    "          [ 0.0000,  0.0000]],\n",
    "            \n",
    "         # green to red (2 to 1)\n",
    "         [[ 0.0001,  0.0000],\n",
    "          [ 0.0000,  0.0001]],\n",
    "\n",
    "         # blue to red (3 to 1)\n",
    "         [[ 1.0000,  0.9000],\n",
    "          [ 0.9000,  1.0000]]],\n",
    "\n",
    "         # red to green (1 to 2)\n",
    "        [[[ 0.0000,  0.5000],\n",
    "          [ 0.0000,  0.5000]],\n",
    "\n",
    "         # green to green (2 to 2)\n",
    "         [[ 1.0000,  0.9000],\n",
    "          [ 0.9000,  1.0000]],\n",
    "\n",
    "         # blue to green (3 to 2)\n",
    "         [[ 0.0000,  0.0000],\n",
    "          [ 0.0000,  0.0000]]],\n",
    "\n",
    "         # red to blue (1 to 3)\n",
    "        [[[ 0.0000,  0.0000],\n",
    "          [ 0.0000,  0.0000]],\n",
    "\n",
    "         # green to blue (2 to 3)\n",
    "         [[ 0.0000,  0.0000],\n",
    "          [ 0.0000,  0.0000]],\n",
    "\n",
    "          # blue to blue (3 to 3)\n",
    "         [[ 0.0000,  0.0000],\n",
    "          [ 0.0000,  0.0000]]]], requires_grad=True)\n",
    "\n",
    "    \n",
    "conv.weight.data = t_new\n",
    "conv.bias.data = torch.tensor([0., 0., 0.])\n",
    "\n",
    "fig, axs = plt.subplots(out_channels, 3)\n",
    "\n",
    "label = ['r', 'g', 'b', 'k']\n",
    "\n",
    "# Loop over the 3x3 grid of subplots\n",
    "for i in range(out_channels):\n",
    "    for j in range(in_channels):\n",
    "        current_image = conv.weight[i, j].detach().numpy()\n",
    "        \n",
    "        axs[i, j].imshow(current_image, cmap='gray', vmin=0, vmax=1)\n",
    "        axs[i, j].set_title(f\"({label[j]} -> {label[i]})\")\n",
    "        axs[i, j].set(xticks=[], yticks=[], xlabel='', ylabel='')\n",
    "        \n",
    "\n",
    "plt.subplots_adjust(wspace=-0.5, hspace=0.5)\n",
    "plt.gcf().text(0.5, 0.02, 'RGB input channels', ha='center')\n",
    "plt.gcf().text(0.02, 0.5, 'RGB output channels', va='center', rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61788455-7520-4c7c-a865-5b2e27c5cd14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "planes = connectx_state.to_feature()\n",
    "tensor_planes = torch.Tensor(planes)\n",
    "after = conv(tensor_planes).detach().numpy()\n",
    "normalised_after = (after - np.min(after)) / (np.max(after) - np.min(after))\n",
    "_ = plt.imshow(normalised_after.transpose(1, 2, 0))\n",
    "_ = plt.axis('off')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
