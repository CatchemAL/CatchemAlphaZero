{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8835fea4-1b51-4a80-8cd1-7a83ada43909",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, clear_output\n",
    "from kaggle_environments import make\n",
    "\n",
    "from pypad.solvers.network_torch import PytorchNeuralNetwork\n",
    "from pypad.solvers.alpha_zero import AlphaZero\n",
    "from pypad.solvers.mcts import MctsSolver\n",
    "from pypad.games import ConnectX, TicTacToe\n",
    "from pypad.views import policies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330e61d5-7854-47a4-94f5-03e5c2b16484",
   "metadata": {},
   "source": [
    "# Visualising Model predictions for TicTacToe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae3834e-af10-4767-96a0-8e1d8fc458f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tictactoe = TicTacToe()\n",
    "tictactoe_state = tictactoe.initial_state([0])\n",
    "tictactoe_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227fe576-7bfa-4a65-9eb5-a3140df92723",
   "metadata": {},
   "outputs": [],
   "source": [
    "tictactoe_network = PytorchNeuralNetwork.create(tictactoe, '..', 2)\n",
    "alpha_zero_ttt = AlphaZero(tictactoe_network)\n",
    "\n",
    "policy = alpha_zero_ttt.raw_policy(tictactoe_state)\n",
    "tictactoe_state.show_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaffa01c-579f-404c-8ac8-b5a6fd33922f",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = alpha_zero_ttt.policy(tictactoe_state, 2)\n",
    "tictactoe_state.show_policy(policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f8e60b-c474-4a74-9d64-7da5c5223d52",
   "metadata": {},
   "source": [
    "# Visualising Model predictions for ConnectX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30a6c86-6e30-4790-b744-adabcb1e23fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "connectx = ConnectX()\n",
    "connectx_state = connectx.initial_state([1,4,3,2,5,6,7,5,4,6,5])\n",
    "connectx_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757bfea1-d49f-4e4f-81c3-4b32aec2e5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "connectx_network = PytorchNeuralNetwork.create(connectx, '..')\n",
    "alpha_zero_connectx = AlphaZero(connectx_network)\n",
    "\n",
    "policy = alpha_zero_connectx.raw_policy(connectx_state)\n",
    "connectx_state.show_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0574578e-9be6-4f1d-9a7a-9b65c3341bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = alpha_zero_connectx.policy(connectx_state, num_mcts_sims=1600)\n",
    "connectx_state.show_policy(policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02dd2568-d328-4ce8-8984-d8d55091ff1c",
   "metadata": {},
   "source": [
    "# Alpha Zero vs Classical Monte Carlo Tree Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb7cebf-45dc-46ae-8988-375e13803387",
   "metadata": {},
   "outputs": [],
   "source": [
    "player_1000 = MctsSolver(1_000)\n",
    "agent_1000 = connectx.create_agent(player_1000)\n",
    "\n",
    "solver = alpha_zero_connectx.as_solver(100)\n",
    "alpha_zero_agent = connectx.create_agent(solver)\n",
    "\n",
    "env = make(connectx.name, debug=True)\n",
    "states = env.run([agent_1000, alpha_zero_agent])\n",
    "env.render(mode=\"ipython\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d996c2-4d79-4a90-934b-6d75ea37b242",
   "metadata": {},
   "source": [
    "# Play against Alpha Zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdf7baa-a437-4a80-b1ab-f89c9d4073f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "game = ConnectX()\n",
    "state = game.initial_state()\n",
    "challenger_plays_as = 1 # play as Player: 1 or 2\n",
    "\n",
    "network = PytorchNeuralNetwork.create(game, '..')\n",
    "alpha_zero = AlphaZero(network)\n",
    "\n",
    "network_old = PytorchNeuralNetwork.create(game, '..', 20)\n",
    "alpha_zero_old = AlphaZero(network_old)\n",
    "\n",
    "def get_move(i: int) -> int:\n",
    "    if i % 2 == challenger_plays_as:\n",
    "        return alpha_zero.select_move(state, 100)\n",
    "    else:\n",
    "        return state.get_input_move()\n",
    "        # return alpha_zero_old.select_move(state, 60)\n",
    "\n",
    "while state.status().is_in_progress:\n",
    "    clear_output(); display(state)\n",
    "    move = get_move(state.num_moves)\n",
    "    state.set_move(move)\n",
    "\n",
    "clear_output(); display(state)\n",
    "if state.status().value > 0:\n",
    "    print('Challenger wins!' if state.played_by == challenger_plays_as else \"AlphaZero wins!\")\n",
    "else:\n",
    "    print(\"It's a draw!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
