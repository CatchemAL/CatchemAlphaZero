{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a6efae-8c45-483e-80f6-852b40036ab4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9160c6-0c14-4658-b62e-0e65b5b78461",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_input_layer(board) -> np.ndarray:\n",
    "    r = (board == 1).astype(float)\n",
    "    g = (board == 2).astype(float)\n",
    "    b = (board == 0).astype(float)\n",
    "    planes = [r, g, b]\n",
    "    return np.stack(planes, axis=-1)\n",
    "\n",
    "board = np.array([\n",
    "    [0, 0, 0, 0, 0, 2, 0],\n",
    "    [0, 0, 0, 0, 0, 1, 2],\n",
    "    [0, 1, 0, 0, 0, 1, 1],\n",
    "    [0, 2, 0, 0, 1, 2, 2],\n",
    "    [0, 2, 0, 0, 2, 2, 1],\n",
    "    [1, 2, 0, 0, 1, 1, 2]\n",
    "])\n",
    "\n",
    "planes = get_input_layer(board)\n",
    "plt.imshow(planes)\n",
    "board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daeddf2f-69bc-471f-9c64-9e03b9bfacf4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "in_channels = 3\n",
    "out_channels = 3\n",
    "kernel_size = 2\n",
    "\n",
    "# Create a convolutional layer with (out_channels x in_channels x kernel_size x kernel_size) weights\n",
    "conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding = 1)\n",
    "\n",
    "weights = conv.weight.detach().numpy()[0]\n",
    "weights.transpose(0, 1, 2)\n",
    "normalised_weights = (weights - np.min(weights)) / (np.max(weights) - np.min(weights))\n",
    "\n",
    "plt.imshow(normalised_weights.transpose(1, 2, 0))\n",
    "\n",
    "conv.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27b75f4-e59c-49a7-a929-b9b62f88eaae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t_new = torch.tensor([\n",
    "         # red to red (1 to 1)\n",
    "        [[[ 1.0000,  0.0000],\n",
    "          [ 0.0000,  1.0000]],\n",
    "            \n",
    "         # green to red (2 to 1)\n",
    "         [[ 1.0000,  0.0000],\n",
    "          [ 0.0000,  1.0000]],\n",
    "\n",
    "         # blue to red (3 to 1)\n",
    "         [[ 1.0000,  0.0000],\n",
    "          [ 0.0000,  1.0000]]],\n",
    "\n",
    "         # red to green (1 to 2)\n",
    "        [[[ 1.0000,  0.0000],\n",
    "          [ 0.0000,  1.0000]],\n",
    "\n",
    "         # green to green (2 to 2)\n",
    "         [[ 1.0000,  1.0000],\n",
    "          [ 1.0000,  1.0000]],\n",
    "\n",
    "         # blue to green (3 to 2)\n",
    "         [[ 1.0000,  0.0000],\n",
    "          [ 0.0000,  1.0000]]],\n",
    "\n",
    "         # red to blue (1 to 3)\n",
    "        [[[ 1.0000,  0.0000],\n",
    "          [ 0.0000,  1.0000]],\n",
    "\n",
    "         # green to blue (2 to 3)\n",
    "         [[ 1.0000,  0.0000],\n",
    "          [ 0.0000,  1.0000]],\n",
    "\n",
    "          # blue to blue (3 to 3)\n",
    "         [[ 1.0000,  1.0000],\n",
    "          [ 1.0000,  1.0000]]]], requires_grad=True)\n",
    "\n",
    "    \n",
    "conv.weight.data = t_new\n",
    "conv.bias.data = torch.tensor([0., 0., 0.])\n",
    "\n",
    "fig, axs = plt.subplots(out_channels, 3)\n",
    "\n",
    "label = ['r', 'g', 'b', 'k']\n",
    "\n",
    "# Loop over the 3x3 grid of subplots\n",
    "for i in range(out_channels):\n",
    "    for j in range(in_channels):\n",
    "        current_image = conv.weight[i, j].detach().numpy()\n",
    "        \n",
    "        axs[i, j].imshow(current_image, cmap='gray')\n",
    "        axs[i, j].set_title(f\"({label[j]} -> {label[i]})\")\n",
    "        axs[i, j].set(xticks=[], yticks=[], xlabel='', ylabel='')\n",
    "        \n",
    "\n",
    "plt.subplots_adjust(wspace=-0.5, hspace=0.5)\n",
    "plt.gcf().text(0.5, 0.02, 'RGB input channels', ha='center')\n",
    "plt.gcf().text(0.02, 0.5, 'RGB output channels', va='center', rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61788455-7520-4c7c-a865-5b2e27c5cd14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tensor_planes = torch.Tensor(planes.transpose(2, 0, 1))\n",
    "after = conv(tensor_planes).detach().numpy().transpose(1, 2, 0)\n",
    "normalised_after = (after - np.min(after)) / (np.max(after) - np.min(after))\n",
    "plt.imshow(normalised_after)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
